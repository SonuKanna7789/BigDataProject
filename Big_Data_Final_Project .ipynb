{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XbxpfKGV4Amv"
   },
   "source": [
    "#                          YouTube Comments Spam Analysis\n",
    "By Team :- Musketeers\n",
    "\n",
    "- Venkata Krishna Sri Chandana Manuri\n",
    "- Sonu Kanna\n",
    "- Hari Krishna Ageer \n",
    "- Poorna Chand addala"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSB2gXXX4pFw"
   },
   "source": [
    "# Data Introduction\n",
    "The dataset is sourced from the UC Irvine Machine Learning Repository and consists of comments from the five most-viewed YouTube videos, labeled as spam or ham. It is suitable for text classification tasks, particularly spam detection. The dataset contains 1,956 comments with fields such as comment ID, author, date, content, and spam labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnSH3gU2OQzZ",
    "outputId": "a1a75652-24ff-4f7f-b3a5-836cb547ac31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
      "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVteAH0A5Ufd"
   },
   "source": [
    "# This  initializes the Spark session and sets up the environment for working with SparkML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFlDVSw3OeMK",
    "outputId": "15d9ebe8-e272-4942-db5e-486d99edd44d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session WebUI Port: 4040\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"spark assignment\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"./spark-warehouse\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run),\n",
    "# this spark session webUI will be on a different port than the default (4040). One way to\n",
    "# identify this part is with the following line. If there was only one spark session running,\n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWqSnBUp6NVN"
   },
   "source": [
    "#  Data Preparation and Preprocessing\n",
    "This code loads multiple CSV files containing YouTube comments from a specified directory.It combines the data from all files into a single Spark DataFrame using the union operation.\n",
    "Finally, the schema and a sample of the combined data frame are displayed for verification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXuboV_5S4uZ"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "071pMBrUOgDY"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "extracted_folder_path = 'youtube+spam+collection.zip'\n",
    "\n",
    "# Extract the zip file to a temporary directory\n",
    "with zipfile.ZipFile(extracted_folder_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/tmp/youtube_spam_collection')\n",
    "\n",
    "# Update the path to the extracted directory\n",
    "extracted_folder_path = '/tmp/youtube_spam_collection'\n",
    "\n",
    "# Now you can list the files in the extracted directory\n",
    "csv_files = [os.path.join(extracted_folder_path, file) for file in os.listdir(extracted_folder_path) if file.endswith('.csv')]\n",
    "\n",
    "dataframes = [spark.read.option(\"header\", True).csv(file) for file in csv_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fi3pVmovOkW0"
   },
   "outputs": [],
   "source": [
    "combined_df = dataframes[0]\n",
    "for df in dataframes[1:]:\n",
    "    combined_df = combined_df.unionByName(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LRDSZ1gXOmad",
    "outputId": "eaa97ffd-e12d-46f6-f031-0b87b56e45b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has 5 columns.\n"
     ]
    }
   ],
   "source": [
    "num_columns = len(combined_df.columns)\n",
    "\n",
    "print(f\"The DataFrame has {num_columns} columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0qxG-qRXOohV",
    "outputId": "0a2013e7-c582-407c-a00c-f992070eb4e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame contains 1961 rows.\n"
     ]
    }
   ],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "row_count = combined_df.count()\n",
    "\n",
    "print(f\"The DataFrame contains {row_count} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "87pDdSvBOr5N",
    "outputId": "7f476b25-2480-41fb-a721-7f156f12b60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+-------+-----+\n",
      "|COMMENT_ID|AUTHOR|DATE|CONTENT|CLASS|\n",
      "+----------+------+----+-------+-----+\n",
      "|         0|     0| 245|      0|    1|\n",
      "+----------+------+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  to count and handle missing values\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# Count missing values in each column\n",
    "missing_values_count = combined_df.select([\n",
    "    count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in combined_df.columns\n",
    "])\n",
    "missing_values_count.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEuC_NcK7vLQ"
   },
   "source": [
    "# Data cleaning\n",
    "\n",
    "This code cleans and preprocesses the dataset by addressing missing and inconsistent values:\n",
    " 1. Missing `DATE` values are replaced with randomly generated dates within a fixed date range.\n",
    " 2. The `CONTENT` column is cleaned by removing unwanted HTML entities, special characters, and extra whitespace.\n",
    " 3. Rows with null `CLASS` values are removed, and only rows where `CLASS` is 0 or 1 are retained.\n",
    " 4. This ensures a consistent, clean, and ready-to-use dataset for further analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkiXAryyOueN",
    "outputId": "9bb015aa-aa3f-4a02-c584-6abfa24ecb77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|          COMMENT_ID|              AUTHOR|                DATE|             CONTENT|CLASS|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|z12rwfnyyrbsefonb...|         Lisa Wellas|2013-12-18 16:24:...|+447935454150 lov...|    1|\n",
      "|z130wpnwwnyuetxcn...|        jason graham|2015-05-29T02:26:...|I always end up c...|    0|\n",
      "|z13vsfqirtavjvu0t...|          Ajkal Khan|2013-12-18 16:24:...|\"my sister just r...|    1|\n",
      "|z12wjzc4eprnvja43...|       Dakota Taylor|2015-05-29T02:13:...|               Cool﻿|    0|\n",
      "|z13xjfr42z3uxdz22...|         Jihad Naser|2013-12-18 16:24:...|Hello I&#39;am fr...|    1|\n",
      "|z133yfmjdur4dvyjr...|     Darrion Johnson|2015-05-29T01:27:...|Wow this video al...|    0|\n",
      "|z12zgrw5furdsn0sc...|            kyeman13|2013-12-18 16:24:...|Go check out my r...|    1|\n",
      "|z12vxdzzds2kzzrzq...|               Damax|2015-05-29T00:41:...|   Almost 1 billion﻿|    0|\n",
      "|z12gxdortqzwhhqas...|Muhammad Asim Mansha|2013-12-18 16:24:...|Aslamu Lykum... F...|    1|\n",
      "|z132wd4ywmicxj2gn...|          JuanPa Rap|2015-05-28T23:23:...|Eminem is idol fo...|    0|\n",
      "|z13si1rx3nnbshdoj...|               Mjt12|2013-12-18 16:24:...|Help me get 50 su...|    1|\n",
      "|z13hwbshcnrhztsw2...|            emily 13|2015-05-28T23:10:...|     i love song :)﻿|    0|\n",
      "|z13nsd141x24yjh2m...|         TheJohnRage|2013-12-18 16:24:...|Alright ladies, i...|    1|\n",
      "|z132ib3jvvqvzjj5t...|       William Davis|2015-05-28T22:42:...|The perfect examp...|    0|\n",
      "|z13puxp4xp35shhfy...|     Ashleigh_ Baise|2015-05-28T22:21:...|The boyfriend was...|    0|\n",
      "|z13kyh3gdnnzdvxjt...|     Lauralyn Karoll|2013-12-18 16:24:...|\"<a href=\"\"https:...|    1|\n",
      "|z12lhjtxlsisx55yu...|         Shirley Lim|2013-12-18 16:24:...|Take a look at th...|    1|\n",
      "|z13hhxajgrnldjmn5...|TMCB production (...|2013-12-18 16:24:...|Check out our Cha...|    1|\n",
      "|z12xurdj0qznephwg...|              Sylith|2015-05-28T21:50:...|Rihanna and Emine...|    0|\n",
      "|z13isdtoikvzjlkij...|      nepaladventure|2013-12-18 16:24:...|Check out this pl...|    1|\n",
      "+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, regexp_replace, trim, col, when,split, size\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "\n",
    "# Define fixed min and max dates\n",
    "min_date = datetime.strptime(\"2013-07-12T22:33:27.916000\", \"%Y-%m-%dT%H:%M:%S.%f\")\n",
    "max_date = datetime.strptime(\"2015-06-05T20:01:23\", \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# Function to generate a random date within the given range\n",
    "def get_random_date_within_range():\n",
    "    random_days = random.randint(0, (max_date - min_date).days)\n",
    "    random_hours = random.randint(0, 23)\n",
    "    random_minutes = random.randint(0, 59)\n",
    "    random_seconds = random.randint(0, 59)\n",
    "    return min_date + timedelta(days=random_days, hours=random_hours, minutes=random_minutes, seconds=random_seconds)\n",
    "\n",
    "# Data cleaning and assigning random dates to nulls in DATE column\n",
    "cleaned_filtered_df = (\n",
    "    combined_df\n",
    "    .withColumn(\n",
    "        'DATE',\n",
    "        when(col('DATE').isNull(), lit(get_random_date_within_range())).otherwise(col('DATE'))\n",
    "    )  # Directly replace missing DATE with random date within range\n",
    "    .filter(col('CLASS').isNotNull())  # Filter out rows where CLASS is null\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"&lt;\", \"<\"))\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"&gt;\", \">\"))\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"&amp;\", \"&\"))\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"ï»¿\", \"\"))\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"<br />\", \"\"))\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"\\\\r\", \" \"))  # Replace carriage return with a space\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"\\\\n\", \" \"))  # Replace newline with a space\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"\\\\t\", \" \"))  # Replace tabs with a space\n",
    "    .withColumn(\"CONTENT\", regexp_replace(\"CONTENT\", \"\\\\s+\", \" \")) # Collapse multiple spaces into one\n",
    "    .withColumn(\"CONTENT\", trim(col(\"CONTENT\")))  # Remove leading and trailing whitespace\n",
    "    .filter((col('CLASS') == 0) | (col('CLASS') == 1))  # Keep only rows where class is 0 or 1\n",
    ")\n",
    "# Show the final cleaned DataFrame with imputed dates\n",
    "cleaned_filtered_df = cleaned_filtered_df.withColumn(\"has_link\", when(col(\"CONTENT\").rlike(\"http|https\"), 1).otherwise(0))\n",
    "## feature engineering\n",
    "# Add a new column for word count\n",
    "cleaned_filtered_df = cleaned_filtered_df.withColumn(\"word_count\", size(split(col(\"CONTENT\"), \" \")))\n",
    "\n",
    "# Show the final cleaned DataFrame with imputed dates and new features\n",
    "cleaned_filtered_df.select(\"CONTENT\", \"DATE\", \"CLASS\", \"has_link\", \"word_count\").show(5, truncate=False)\n",
    "# Show the final cleaned DataFrame with imputed dates\n",
    "cleaned_filtered_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EQv3UiWO1TA",
    "outputId": "17366209-e3f7-428b-8f08-78d1b499fbca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|DATE                      |CONTENT                                                                                                                                                                                                          |CLASS|\n",
      "+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|2013-12-18 16:24:27.916   |+447935454150 lovely girl talk to me xxx﻿                                                                                                                                                                        |1    |\n",
      "|2015-05-29T02:26:10.652000|I always end up coming back to this song﻿                                                                                                                                                                        |0    |\n",
      "|2013-12-18 16:24:27.916   |\"my sister just received over 6,500 new <a rel=\"\"nofollow\"\" class=\"\"ot-hashtag\"\" href=\"\"https://plus.google.com/s/%23active\"\">#active</a> youtube views Right now. The only thing she used was pimpmyviews. com﻿\"|1    |\n",
      "|2015-05-29T02:13:07.810000|Cool﻿                                                                                                                                                                                                            |0    |\n",
      "|2013-12-18 16:24:27.916   |Hello I&#39;am from Palastine﻿                                                                                                                                                                                   |1    |\n",
      "+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned and filtered DataFrame\n",
    "cleaned_filtered_df.select(\"DATE\",\"CONTENT\", \"CLASS\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kIwCXst7O3CM",
    "outputId": "ca59ed2a-246c-45b6-d3d6-166d357d7a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+-------+-----+\n",
      "|COMMENT_ID|AUTHOR|DATE|CONTENT|CLASS|\n",
      "+----------+------+----+-------+-----+\n",
      "|         0|     0|   0|      0|    0|\n",
      "+----------+------+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example to count and handle missing values\n",
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "# Count missing values in each column\n",
    "missing_values_count = cleaned_filtered_df .select([\n",
    "    count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in cleaned_filtered_df .columns\n",
    "])\n",
    "missing_values_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBAV3Yz-O5Ke"
   },
   "outputs": [],
   "source": [
    "# Register the DataFrame as a persistent table\n",
    "cleaned_filtered_df.write.mode('overwrite').saveAsTable('youtube_spam_cleaned_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1txw_xu1O7Bc",
    "outputId": "f71c7dd0-3ffc-410d-e526-cc7061410c2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+-------------+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|COMMENT_ID                         |AUTHOR       |DATE                      |CONTENT                                                                                                                                                                                                          |CLASS|\n",
      "+-----------------------------------+-------------+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "|z12rwfnyyrbsefonb232i5ehdxzkjzjs2  |Lisa Wellas  |2013-12-18 16:24:27.916   |+447935454150 lovely girl talk to me xxx﻿                                                                                                                                                                        |1    |\n",
      "|z130wpnwwnyuetxcn23xf5k5ynmkdpjrj04|jason graham |2015-05-29T02:26:10.652000|I always end up coming back to this song﻿                                                                                                                                                                        |0    |\n",
      "|z13vsfqirtavjvu0t22ezrgzyorwxhpf3  |Ajkal Khan   |2013-12-18 16:24:27.916   |\"my sister just received over 6,500 new <a rel=\"\"nofollow\"\" class=\"\"ot-hashtag\"\" href=\"\"https://plus.google.com/s/%23active\"\">#active</a> youtube views Right now. The only thing she used was pimpmyviews. com﻿\"|1    |\n",
      "|z12wjzc4eprnvja4304cgbbizuved35wxcs|Dakota Taylor|2015-05-29T02:13:07.810000|Cool﻿                                                                                                                                                                                                            |0    |\n",
      "|z13xjfr42z3uxdz2223gx5rrzs3dt5hna  |Jihad Naser  |2013-12-18 16:24:27.916   |Hello I&#39;am from Palastine﻿                                                                                                                                                                                   |1    |\n",
      "+-----------------------------------+-------------+--------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM youtube_spam_cleaned_data\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W59gOnWlO9a3",
    "outputId": "17bdf23e-1c1e-4bc4-e6c8-11b93c6441c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----+-------+-----+\n",
      "|COMMENT_ID|AUTHOR|DATE|CONTENT|CLASS|\n",
      "+----------+------+----+-------+-----+\n",
      "+----------+------+----+-------+-----+\n",
      "\n",
      "Number of rows with identical values across all columns: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Start by comparing the first column with itself to initialize\n",
    "filter_condition = (col(cleaned_filtered_df.columns[0]) == col(cleaned_filtered_df.columns[1]))\n",
    "\n",
    "# Loop through the rest of the columns and append comparison conditions\n",
    "for col_name in cleaned_filtered_df.columns[2:]:\n",
    "    filter_condition = filter_condition & (col(cleaned_filtered_df.columns[0]) == col(col_name))\n",
    "\n",
    "# Apply the filter\n",
    "same_value_rows = cleaned_filtered_df.filter(filter_condition)\n",
    "\n",
    "# Show rows where all column values are the same\n",
    "same_value_rows.show(truncate=False)\n",
    "\n",
    "# Count such rows\n",
    "same_value_rows_count = same_value_rows.count()\n",
    "print(f\"Number of rows with identical values across all columns: {same_value_rows_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XSQjmQG8emU"
   },
   "source": [
    "# Machine Learning Models Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGbI74zGPO2o"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Data Preprocessing\n",
    "# Convert labels to numeric format\n",
    "indexer = StringIndexer(inputCol=\"CLASS\", outputCol=\"label\")\n",
    "processed_data = indexer.fit(cleaned_filtered_df).transform(cleaned_filtered_df)\n",
    "\n",
    "# Tokenize and remove stop words\n",
    "tokenizer = Tokenizer(inputCol=\"CONTENT\", outputCol=\"words\")\n",
    "words_data = tokenizer.transform(processed_data)\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "words_data = remover.transform(words_data)\n",
    "\n",
    "# Convert words to vector using HashingTF and IDF\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=20)\n",
    "featurized_data = hashing_tf.transform(words_data)\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"text_features\")\n",
    "idf_model = idf.fit(featurized_data)\n",
    "rescaled_data = idf_model.transform(featurized_data)\n",
    "\n",
    "# Combine TF-IDF features with new engineered features into a single feature vector\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"text_features\", \"has_link\", \"word_count\"],  # Combine all relevant features\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "final_data = assembler.transform(rescaled_data)\n",
    "\n",
    "# Split the data into training and test sets with 80% for training and 20% for testing\n",
    "train_data, test_data = final_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "El7IVt4FT-yl"
   },
   "source": [
    "Classification Model Training without Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jW9CQtj8PROv",
    "outputId": "83a1f2c9-cd89-41ea-bf61-491f55b5c0f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "                 Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
      "0  Logistic Regression  0.773684   0.753846  0.794595  0.773684  0.774220\n",
      "1        Decision Tree  0.792105   0.776042  0.805405  0.790451  0.792446\n"
     ]
    }
   ],
   "source": [
    "# Evaluators\n",
    "classification_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "binary_classification_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# Model 1: Logistic Regression (Classification)\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "lr_model = lr.fit(train_data)\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Accuracy, Precision, Recall, F1-Score, AUC-ROC for Logistic Regression\n",
    "lr_accuracy = classification_evaluator.evaluate(lr_predictions)\n",
    "lr_auc = binary_classification_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "# Assuming labels are in the 'label' column and predictions in 'prediction' column\n",
    "lr_precision = precision_score(lr_predictions.select(\"label\").toPandas(), lr_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "lr_recall = recall_score(lr_predictions.select(\"label\").toPandas(), lr_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "lr_f1 = f1_score(lr_predictions.select(\"label\").toPandas(), lr_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "\n",
    "# Model 2: Decision Tree (Classification)\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "dt_model = dt.fit(train_data)\n",
    "dt_predictions = dt_model.transform(test_data)\n",
    "\n",
    "# Accuracy, Precision, Recall, F1-Score, AUC-ROC for Decision Tree\n",
    "dt_accuracy = classification_evaluator.evaluate(dt_predictions)\n",
    "dt_auc = binary_classification_evaluator.evaluate(dt_predictions)\n",
    "\n",
    "dt_precision = precision_score(dt_predictions.select(\"label\").toPandas(), dt_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "dt_recall = recall_score(dt_predictions.select(\"label\").toPandas(), dt_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "dt_f1 = f1_score(dt_predictions.select(\"label\").toPandas(), dt_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "\n",
    "# Creating a summary table of results\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Decision Tree\"],\n",
    "    \"Accuracy\": [lr_accuracy, dt_accuracy],\n",
    "    \"Precision\": [lr_precision, dt_precision],\n",
    "    \"Recall\": [lr_recall, dt_recall],\n",
    "    \"F1-Score\": [lr_f1, dt_f1],\n",
    "    \"AUC-ROC\": [lr_auc, dt_auc]\n",
    "})\n",
    "\n",
    "# Displaying results\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxE1xzqQ-JYS"
   },
   "source": [
    "**Logistic Regression**:\n",
    "Logistic Regression is ideal for binary classification tasks like spam detection.\n",
    "It provides clear probabilistic outputs, aiding in decision-making based on spam likelihood.\n",
    "Achieved 77.4% accuracy and an AUC-ROC of 77.4%, showing reliable overall performance.\n",
    "Its 79.5% recall ensures it identifies most spam comments, though precision (75.4%) is slightly lower.\n",
    "A simple, interpretable model that serves as a robust baseline for this problem.\n",
    "\n",
    "\n",
    "**Decision Tree**:\n",
    "Decision Tree effectively handles non-linear patterns and mixed data types in spam detection.\n",
    "Outperformed Logistic Regression with 79.2% accuracy and an AUC-ROC of 79.2%.\n",
    "Its higher precision (77.6%) and recall (80.5%) make it better at detecting spam while minimizing false positives.\n",
    "F1-Score (79.0%) confirms it balances spam identification and avoiding false alarms.\n",
    "An interpretable, high-performing model, making it ideal for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqn3FC4DWHYf",
    "outputId": "c5c90bfa-06dc-4078-8c55-ac428acb22d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "                    Model  Accuracy      RMSE       MAE  R-squared\n",
      "0           Random Forest  0.778947  0.470162  0.221053   0.067348\n",
      "1  Gradient-Boosted Trees  0.781579  0.467355  0.218421   0.078451\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Evaluators\n",
    "classification_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", metricName=\"accuracy\")\n",
    "regression_evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "clustering_evaluator = ClusteringEvaluator(featuresCol='features', metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "\n",
    "# Model 3: Random Forest (Classification)\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "rf_model = rf.fit(train_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "\n",
    "# Accuracy for Random Forest\n",
    "rf_accuracy = classification_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "# RMSE, MAE for Random Forest\n",
    "rf_rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(rf_predictions)\n",
    "rf_mae = regression_evaluator.setMetricName(\"mae\").evaluate(rf_predictions)\n",
    "\n",
    "# R-squared for Random Forest (custom calculation)\n",
    "rf_r2 = 1 - (rf_rmse ** 2 / (rf_predictions.select(\"label\").rdd.map(lambda row: row[0]).mean() ** 2))\n",
    "\n",
    "# Model 4: Gradient-Boosted Trees (Classification)\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "gbt_model = gbt.fit(train_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# Accuracy for Gradient-Boosted Trees\n",
    "gbt_accuracy = classification_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "# RMSE, MAE for Gradient-Boosted Trees\n",
    "gbt_rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(gbt_predictions)\n",
    "gbt_mae = regression_evaluator.setMetricName(\"mae\").evaluate(gbt_predictions)\n",
    "\n",
    "# R-squared for Gradient-Boosted Trees (custom calculation)\n",
    "gbt_r2 = 1 - (gbt_rmse ** 2 / (gbt_predictions.select(\"label\").rdd.map(lambda row: row[0]).mean() ** 2))\n",
    "\n",
    "# Creating a summary table of results\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Random Forest\", \"Gradient-Boosted Trees\"],\n",
    "    \"Accuracy\": [rf_accuracy, gbt_accuracy],\n",
    "    \"RMSE\": [rf_rmse, gbt_rmse],\n",
    "    \"MAE\": [rf_mae, gbt_mae],\n",
    "    \"R-squared\": [rf_r2, gbt_r2],\n",
    "})\n",
    "\n",
    "# Displaying results\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDYC-gqB_nlf"
   },
   "source": [
    "**Random Forest Classifier**:\n",
    "Random Forest is an ensemble learning method effective for binary classification tasks like spam detection.\n",
    "Achieved an accuracy of 77.89%, demonstrating good performance in distinguishing spam and non-spam comments.\n",
    "RMSE (0.470) and MAE (0.221) indicate reasonable prediction error magnitudes.\n",
    "R-squared (0.067) highlights some variance capture but shows potential for improvement with tuning.\n",
    "It was chosen for its robustness, interpretability, and ability to handle complex, diverse datasets effectively.\n",
    "\n",
    "\n",
    "**Gradient-Boosted Trees (GBT) Classifier**:\n",
    "Gradient-Boosted Trees are a powerful ensemble model optimized for classification tasks through boosting.\n",
    "Achieved a higher accuracy of 78.16%, surpassing Random Forest in overall precision and recall.\n",
    "RMSE (0.467) and MAE (0.218) metrics demonstrate fewer prediction errors than Random Forest.\n",
    "R-squared (0.078) shows its superior ability to explain the variance in the dataset.\n",
    "We chose GBT for its adaptability to intricate patterns, making it highly suitable for this spam detection task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8IjA4LUPdTr"
   },
   "source": [
    "Logictic regression with hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEwzKY8VPaFS",
    "outputId": "0c5972ec-5781-48b0-d588-6557d81ee288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7710526315789473\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Create a parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.01, 0.1, 1.0, 10.0]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(lr.maxIter, [50, 100, 200]) \\\n",
    "    .build()\n",
    "\n",
    "# Define evaluator for accuracy\n",
    "classification_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='accuracy'\n",
    ")\n",
    "\n",
    "# Create a CrossValidator for model selection\n",
    "crossval = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=classification_evaluator,\n",
    "    numFolds=5  # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "# Perform cross-validation and choose the best set of parameters\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "best_lr_model = cv_model.bestModel\n",
    "lr_predictions = best_lr_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model's performance for accuracy\n",
    "lr_accuracy = classification_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(lr_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bh00CEfaeaLb",
    "outputId": "cbab5e29-183e-4f99-ef20-03dab7974a2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics:\n",
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "0  Logistic Regression  0.771053       0.75  0.794595  0.771654\n"
     ]
    }
   ],
   "source": [
    "lr_auc = binary_classification_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "# Assuming labels are in the 'label' column and predictions in 'prediction' column\n",
    "lr_precision = precision_score(lr_predictions.select(\"label\").toPandas(), lr_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "lr_recall = recall_score(lr_predictions.select(\"label\").toPandas(), lr_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "lr_f1 = f1_score(lr_predictions.select(\"label\").toPandas(), lr_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "# Creating a summary table of results\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\"],\n",
    "    \"Accuracy\": [lr_accuracy],\n",
    "    \"Precision\": [lr_precision],\n",
    "    \"Recall\": [lr_recall],\n",
    "    \"F1-Score\": [lr_f1],\n",
    "})\n",
    "\n",
    "# Displaying results\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUK_6OSjgfBY"
   },
   "source": [
    "Decision Tree with Hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PDZK5eDMPg8v",
    "outputId": "cebead31-d209-4de5-80b0-a02b4b30e5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Parameters: {Param(parent='DecisionTreeClassifier_e45c6362d88f', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='featuresCol', doc='features column name.'): 'features', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='labelCol', doc='label column name.'): 'label', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='DecisionTreeClassifier_e45c6362d88f', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='DecisionTreeClassifier_e45c6362d88f', name='seed', doc='random seed.'): -3348471374994817850}\n",
      "Decision Tree Accuracy: 0.8000\n",
      "Model Evaluation Metrics:\n",
      "          Model  Accuracy  Precision    Recall  F1-Score\n",
      "0  Decsion Tree       0.8   0.822485  0.751351  0.785311\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Create a parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder().addGrid(dt.maxDepth, [2, 5, 10, 20]).addGrid(dt.minInstancesPerNode, [1, 5, 10]).addGrid(dt.minInfoGain, [0.0, 0.01, 0.1]) .build()\n",
    "\n",
    "# Define an evaluator for classification\n",
    "classification_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='accuracy'\n",
    ")\n",
    "\n",
    "# Create a CrossValidator for model selection\n",
    "crossval = CrossValidator(\n",
    "    estimator=dt,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=classification_evaluator,\n",
    "    numFolds=5  # Number of cross-validation folds\n",
    ")\n",
    "\n",
    "# Perform cross-validation and choose the best set of parameters\n",
    "cv_model = crossval.fit(train_data)\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "best_dt_model = cv_model.bestModel\n",
    "dt_predictions = best_dt_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "dt_accuracy = classification_evaluator.evaluate(dt_predictions)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Best Model Parameters: {best_dt_model.extractParamMap()}\")\n",
    "print(f\"Decision Tree Accuracy: {dt_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Assuming labels are in the 'label' column and predictions in 'prediction' column\n",
    "dt_precision = precision_score(dt_predictions.select(\"label\").toPandas(), dt_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "dt_recall = recall_score(dt_predictions.select(\"label\").toPandas(), dt_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "dt_f1 = f1_score(dt_predictions.select(\"label\").toPandas(), dt_predictions.select(\"prediction\").toPandas(), average='binary')\n",
    "# Creating a summary table of results\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Decsion Tree\"],\n",
    "    \"Accuracy\": [dt_accuracy],\n",
    "    \"Precision\": [dt_precision],\n",
    "    \"Recall\": [dt_recall],\n",
    "    \"F1-Score\": [dt_f1],\n",
    "})\n",
    "\n",
    "# Displaying results\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBNoFrXUPn8G"
   },
   "source": [
    "Random forest with Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVsUrY-iPlPO",
    "outputId": "60a4aaac-375c-4730-8e97-07d9d3ad0735"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {Param(parent='RandomForestClassifier_ccb32a3d1d33', name='bootstrap', doc='Whether bootstrap samples are used when building trees.'): True, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='featuresCol', doc='features column name.'): 'features', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='labelCol', doc='label column name.'): 'label', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 32, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 5, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='numTrees', doc='Number of trees to train (>= 1).'): 50, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='predictionCol', doc='prediction column name.'): 'prediction', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction', Param(parent='RandomForestClassifier_ccb32a3d1d33', name='seed', doc='random seed.'): -2920798704302981612, Param(parent='RandomForestClassifier_ccb32a3d1d33', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0}\n",
      "Random Forest Accuracy: 0.7895\n",
      "Random Forest RMSE: 0.4588\n",
      "Random Forest MAE: 0.2105\n",
      "Random Forest R-squared: 0.1573\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Evaluator for both models\n",
    "classification_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='accuracy'\n",
    ")\n",
    "\n",
    "# Regression Evaluators\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='rmse'\n",
    ")\n",
    "\n",
    "mae_evaluator = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='mae'\n",
    ")\n",
    "\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    metricName='r2'\n",
    ")\n",
    "\n",
    "# ----------------------- Hypertuning Random Forest ----------------------- #\n",
    "# Initialize Random Forest classifier\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Create parameter grid for Random Forest\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10, 20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 20]) \\\n",
    "    .addGrid(rf.minInstancesPerNode, [1, 5]) \\\n",
    "    .addGrid(rf.maxBins, [32, 64]) \\\n",
    "    .build()\n",
    "\n",
    "# CrossValidator for Random Forest\n",
    "rf_crossval = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=rf_paramGrid,\n",
    "    evaluator=classification_evaluator,\n",
    "    numFolds=5  # 5-fold cross-validation\n",
    ")\n",
    "\n",
    "# Train and select the best Random Forest model\n",
    "rf_cv_model = rf_crossval.fit(train_data)\n",
    "best_rf_model = rf_cv_model.bestModel\n",
    "rf_predictions = best_rf_model.transform(test_data)\n",
    "\n",
    "# Evaluate performance with classification evaluator (accuracy)\n",
    "rf_accuracy = classification_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "# Evaluate performance with regression evaluators (RMSE, MAE, R-squared)\n",
    "rf_rmse = rmse_evaluator.evaluate(rf_predictions)\n",
    "rf_mae = mae_evaluator.evaluate(rf_predictions)\n",
    "rf_r2 = r2_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "# Output Random Forest results\n",
    "print(f\"Best Random Forest Parameters: {best_rf_model.extractParamMap()}\")\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Random Forest RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"Random Forest MAE: {rf_mae:.4f}\")\n",
    "print(f\"Random Forest R-squared: {rf_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM3rAyZNP6UF"
   },
   "source": [
    " Hypertuning Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyOn0gxUP6cu",
    "outputId": "d64aa0a5-f24c-43be-cd60-054db4bc3cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient-Boosted Trees Accuracy: 0.7974\n",
      "Gradient-Boosted Trees RMSE: 0.4501\n",
      "Gradient-Boosted Trees MAE: 0.2026\n",
      "Gradient-Boosted Trees R-squared: 0.1889\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Initialize Gradient-Boosted Trees classifier\n",
    "gbt = GBTClassifier(featuresCol='features', labelCol='label')\n",
    "\n",
    "# Create parameter grid for Gradient-Boosted Trees\n",
    "gbt_paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(gbt.maxDepth, [3, 5, 10])\\\n",
    "    .addGrid(gbt.maxIter, [10, 20, 50])\\\n",
    "    .addGrid(gbt.stepSize, [0.01, 0.1, 0.2])\\\n",
    "    .build()\n",
    "\n",
    "# CrossValidator for Gradient-Boosted Trees\n",
    "gbt_crossval = CrossValidator(\n",
    "    estimator=gbt,\n",
    "    estimatorParamMaps=gbt_paramGrid,\n",
    "    evaluator=classification_evaluator,\n",
    "    numFolds=5  # 5-fold cross-validation\n",
    ")\n",
    "\n",
    "# Train and select the best Gradient-Boosted Trees model\n",
    "gbt_cv_model = gbt_crossval.fit(train_data)\n",
    "best_gbt_model = gbt_cv_model.bestModel\n",
    "gbt_predictions = best_gbt_model.transform(test_data)\n",
    "gbt_accuracy = classification_evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "# Initialize evaluators for regression metrics\n",
    "regression_evaluator_rmse = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "regression_evaluator_mae = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"mae\"\n",
    ")\n",
    "\n",
    "regression_evaluator_r2 = RegressionEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "\n",
    "# Calculate RMSE, MAE, and R-squared\n",
    "rmse = regression_evaluator_rmse.evaluate(gbt_predictions)\n",
    "mae = regression_evaluator_mae.evaluate(gbt_predictions)\n",
    "r2 = regression_evaluator_r2.evaluate(gbt_predictions)\n",
    "\n",
    "# Output Gradient-Boosted Trees results with regression metrics\n",
    "print(f\"Gradient-Boosted Trees Accuracy: {gbt_accuracy:.4f}\")\n",
    "print(f\"Gradient-Boosted Trees RMSE: {rmse:.4f}\")\n",
    "print(f\"Gradient-Boosted Trees MAE: {mae:.4f}\")\n",
    "print(f\"Gradient-Boosted Trees R-squared: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "froYhqZCDJlR"
   },
   "source": [
    "## Summary\n",
    "\n",
    "### Chosen Model: Gradient-Boosted Trees (GBT)\n",
    "\n",
    "Gradient-Boosted Trees is the recommended model for the spam detection problem because it demonstrates:\n",
    "\n",
    "High Accuracy and Robustness: While Decision Tree achieved 80% accuracy, Gradient-Boosted Trees provides a comparable 79.74% accuracy but excels in Recall, F1-Score, and AUC-ROC, indicating better spam detection capability.\n",
    "Balanced Metrics: Gradient-Boosted Trees minimizes false positives and false negatives, crucial for spam detection.\n",
    "\n",
    "\n",
    "**Why Decision Tree Was Not Selected**: Despite slightly higher accuracy, Decision Tree is prone to overfitting and lacks the robustness of ensemble methods, which limits generalization to unseen data.\n",
    "\n",
    "\n",
    "**Future Improvements**\n",
    "Data Collection: Augment the dataset with more labeled examples for better generalization.\n",
    "Advanced Features: Incorporate embeddings (e.g., Word2Vec, BERT) for richer text representation.\n",
    "Hybrid Models: Explore ensembles combining Gradient-Boosted Trees and Random Forest.\n",
    "Class Imbalance: Address imbalance with techniques like SMOTE or weighted loss functions.\n",
    "\n",
    "Gradient-Boosted Trees provides the best balance of accuracy, generalization, and robustness, making it ideal for scalable spam detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NX7oD9uCRq_"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the evaluator\n",
    "classification_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Define the models and cross-validation for each\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(featuresCol='features', labelCol='label'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(featuresCol='features', labelCol='label'),\n",
    "    \"Random Forest\": RandomForestClassifier(featuresCol='features', labelCol='label'),\n",
    "    \"Gradient-Boosted Trees\": GBTClassifier(featuresCol='features', labelCol='label')\n",
    "}\n",
    "\n",
    "# Create hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": ParamGridBuilder().addGrid(LogisticRegression.regParam, [0.01, 0.1, 1.0]).addGrid(LogisticRegression.elasticNetParam, [0.0, 0.5, 1.0]).addGrid(LogisticRegression.maxIter, [10, 50, 100]).build(),\n",
    "    \"Decision Tree\": ParamGridBuilder().addGrid(DecisionTreeClassifier.maxDepth, [3, 5, 10]).addGrid(DecisionTreeClassifier.minInstancesPerNode, [1, 2, 5]).build(),\n",
    "    \"Random Forest\": ParamGridBuilder().addGrid(RandomForestClassifier.maxDepth, [5, 10, 20]).addGrid(RandomForestClassifier.numTrees, [20, 50, 100]).build(),\n",
    "    \"Gradient-Boosted Trees\": ParamGridBuilder().addGrid(GBTClassifier.maxDepth, [3, 5, 10]).addGrid(GBTClassifier.maxIter, [10, 20, 50]).addGrid(GBTClassifier.stepSize, [0.01, 0.1, 0.2]).build(),\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "for model_name, model in models.items():\n",
    "    param_grid = param_grids[model_name]\n",
    "\n",
    "    # Create the CrossValidator for the current model\n",
    "    crossval = CrossValidator(\n",
    "        estimator=model,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=classification_evaluator,\n",
    "        numFolds=5  # 5-fold cross-validation\n",
    "    )\n",
    "\n",
    "    # Train the model using cross-validation\n",
    "    cv_model = crossval.fit(train_data)\n",
    "    best_model = cv_model.bestModel\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = best_model.transform(test_data)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = classification_evaluator.evaluate(predictions)\n",
    "    precision_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='weightedPrecision')\n",
    "    precision = precision_evaluator.evaluate(predictions)\n",
    "\n",
    "    recall_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='weightedRecall')\n",
    "    recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "    f1_evaluator = MulticlassClassificationEvaluator(labelCol='label', predictionCol='prediction', metricName='f1')\n",
    "    f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "    # Collect results for each model\n",
    "    results.append({\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1_score\n",
    "    })\n",
    "\n",
    "# Create a DataFrame for the results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqowtOcWCqp1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
